{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2de92dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-27 20:49:25.064886: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-27 20:49:25.519616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 364 MB memory:  -> device: 0, name: NVIDIA TITAN V, pci bus id: 0000:a1:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "from ketos.data_handling import selection_table as sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370838e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/data/WCS/' # Path to the folder that contains all the audio files\n",
    "test_annot_file='CB300_test'\n",
    "annot_df=pd.read_csv('../../annotations/test/'+test_annot_file+'.csv')\n",
    "segment_length, segment_step = 3.0, 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afac6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_annot(annot_df, delete_columns=['Selection', 'View']):\n",
    "    \"\"\" Delete unwanted columns from the annotations dataframe and \n",
    "        apply necessary pre-processing on the annotation columns\n",
    "     \n",
    "        Args:\n",
    "            annot_df: pandas DataFrame\n",
    "                Annotation table.\n",
    "            delete_columns: list\n",
    "                List of columns to delete from the annotations dataframe\n",
    "                default values ('Selection', 'View')\n",
    "\n",
    "        Returns:\n",
    "            annot_df: pandas DataFrame\n",
    "                Annotation table after pre-processing\n",
    "\n",
    "    \"\"\"\n",
    "    # Delete unnecessary columns\n",
    "    for column in delete_columns:\n",
    "        del annot_df[column]\n",
    "        \n",
    "    annot_df.rename({'Begin Path': 'filename',\n",
    "                    'File Offset (s)': 'start',\n",
    "                    'species': 'label'}, axis='columns', inplace =True)\n",
    "\n",
    "    # Modify filepath (Discard the drive location (e.g., D:/))\n",
    "    annot_df['filename']=annot_df['filename'].apply(lambda x: x[3:len(x)]) \n",
    "    # Modify filepath to replace \\ with / in the filename\n",
    "    annot_df['filename']=annot_df['filename'].apply(lambda x: x.replace(\"\\\\\", \"/\")) \n",
    "    # Modify filepath to add the data root dir (/data/WCS/)\n",
    "    annot_df['filename']=annot_df['filename'].apply(lambda x: data_dir+x)\n",
    "    # Calculate End time\n",
    "    annot_df['end']=annot_df['start']+annot_df['Delta Time (s)']\n",
    "    return annot_df\n",
    "\n",
    "def extract_annot_by_file(df_annot):\n",
    "    \"\"\" Store the annotations of each file into a dictionary\n",
    "     \n",
    "        Args:\n",
    "            annot_df: pandas DataFrame\n",
    "                Annotation table.\n",
    "\n",
    "        Returns:\n",
    "            annot_by_file_dict: dict\n",
    "                Dictionary of annotations stored for each file\n",
    "\n",
    "    \"\"\"\n",
    "    annot_by_file_dict=dict()\n",
    "\n",
    "    # Extract all distinct filename\n",
    "    unique_filenames=df_annot['filename'].unique()\n",
    "\n",
    "    # Separate annotations by each filename\n",
    "    for filename in unique_filenames:\n",
    "        target_matched_annot_df = df_annot[df_annot['filename'].str.find(filename) != -1]\n",
    "        annot_by_file_dict[filename]=target_matched_annot_df\n",
    "    return annot_by_file_dict\n",
    "\n",
    "\n",
    "def check_overlap(start, end, annotation_df, search_class_label):\n",
    "    \"\"\" Check if a selection has overlap in the annotation table of a specific file\n",
    "     \n",
    "        Args:\n",
    "            start: float\n",
    "                Selection start time.\n",
    "            end: float\n",
    "                Selection end time.\n",
    "            annotation_df: pandas DataFrame\n",
    "                Annotation table.\n",
    "            search_class_label: int\n",
    "                Class label to search in the annotation table.\n",
    "\n",
    "        Returns:\n",
    "            overlap_found: bool\n",
    "                Returns True if there is overlap found, otherwise, returns False if the specifed selection does not match in the annotation dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    overlap_found = False\n",
    "    for annot_index, annot_row in annotation_df.iterrows():\n",
    "        if((annot_row['start'] <= start <= annot_row['end']) or \n",
    "           (annot_row['start'] <= end <= annot_row['end']) or\n",
    "           (start <= annot_row['start'] and end >= annot_row['end']) and\n",
    "           annot_row['label']==search_class_label):\n",
    "            overlap_found = True\n",
    "            break\n",
    "    return overlap_found\n",
    "\n",
    "def validate_annot_detections_serial(annot_df, detection_df):\n",
    "    \"\"\" Function to check if the annotation and detection serial is matching (filename and start time)\n",
    "        It also prints the row index if any row of the annot_df and detection_df doesn't match.\n",
    "\n",
    "        The serial of both dataframe is required to be same so that we can easily use the scikit-learn \n",
    "        packages for performance measurements.\n",
    "     \n",
    "        Args:\n",
    "            annot_df: pandas DataFrame\n",
    "                Annotation table.\n",
    "            detection_df: pandas DataFrame\n",
    "                Model detection dataframe.\n",
    "\n",
    "        Returns:\n",
    "            valid_flag: bool\n",
    "                Returns True if both dataframes are in the same serial, Else returns False.\n",
    "\n",
    "    \"\"\"\n",
    "    valid_flag=True\n",
    "    for i in range(len(annot_df['filename'].values)):\n",
    "        if(((annot_df['filename'].values)[i]!=(detection_df['filename'].values)[i]) or \n",
    "           ((annot_df['start'].values)[i]!=(detection_df['start'].values)[i])):\n",
    "            print(\"Not equal at, \", i)\n",
    "            print(\"Annot: \", annot_df.iloc[i], \"Detection: \", detection_df.iloc[i])\n",
    "            valid_flag=False\n",
    "    return valid_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef56c0f",
   "metadata": {},
   "source": [
    "# Process annotation to add segmentation that matches with model detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb63b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df=preprocess_annot(annot_df)\n",
    "\n",
    "# Get all files' duration in time\n",
    "unique_filenames=annot_df['filename'].unique()\n",
    "duration_list=[]\n",
    "for filename in unique_filenames:\n",
    "    duration_list.append(librosa.get_duration(filename=filename))\n",
    "    \n",
    "target_files_with_len = pd.DataFrame({'filename':unique_filenames, \n",
    "                                      'duration':duration_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e520bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize annotation table format\n",
    "annot, label_dict = sl.standardize(annot_df, return_label_dict=True, trim_table=True)\n",
    "\n",
    "segmented_annot = sl.segment_files(table=target_files_with_len, length=segment_length, step=segment_step, pad=True)\n",
    "\n",
    "# Resetting index to change the multi-indexed dataframe to normal columns\n",
    "annot=annot.reset_index()\n",
    "del annot['annot_id']\n",
    "segmented_annot=segmented_annot.reset_index()\n",
    "del segmented_annot['sel_id']\n",
    "\n",
    "# Store annotations of each file to a dictionary\n",
    "annot_by_file_dict=extract_annot_by_file(annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9627d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the segmented annotation table with appropriate label\n",
    "for index, row in segmented_annot.iterrows():\n",
    "    annot_filtered_by_filename_df=annot_by_file_dict[row['filename']]\n",
    "    # For multiple classes, change this part. Along with 1, also add conditions for other labels\n",
    "    overlap_annot_result=check_overlap(row['start'], row['end'], annot_filtered_by_filename_df, 1)\n",
    "    if(overlap_annot_result):\n",
    "        segmented_annot.at[index, 'label']=1\n",
    "    else:\n",
    "        segmented_annot.at[index, 'label']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65296b9e",
   "metadata": {},
   "source": [
    "# Read model detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94e4a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_detection_filename='detections_bh_detector_v02_'+test_annot_file+'.csv' # Change the model detections file name for diff versions of model/detector\n",
    "model_detections_df=pd.read_csv(\"../../results/model_detections/\"+model_detection_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec38660",
   "metadata": {},
   "source": [
    "# Sort annotations and model detections. Check validity of correct serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3cd454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented_annot=segmented_annot.sort_values(['filename', 'start'], ascending=[True, True])\n",
    "model_detections_df=model_detections_df.sort_values(['filename', 'start'], ascending=[True, True])\n",
    "validate_annot_detections_serial(segmented_annot, model_detections_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6618c92",
   "metadata": {},
   "source": [
    "# Convert model detection score to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a44cdf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold value to detect a prediction as Bowhead (BH)\n",
    "threshold=0.2\n",
    "def get_label_from_score(value):\n",
    "    \"\"\"\n",
    "        Returns label (1 if BH, else 0) based on prediction score\n",
    "        Args:\n",
    "            value: int\n",
    "                Prediction score.\n",
    "\n",
    "        Returns:\n",
    "            0 or 1. \n",
    "            1 meaning detected as a BH, 0 means other/background\n",
    "    \n",
    "    \"\"\"\n",
    "    if(value>threshold):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "model_detections_df['label']=model_detections_df['score'].apply(get_label_from_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da97760",
   "metadata": {},
   "source": [
    "# Calculate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee56613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Positive (BH)       0.98      0.85      0.91     89889\n",
      "     Negative       0.11      0.48      0.17      3311\n",
      "\n",
      "     accuracy                           0.84     93200\n",
      "    macro avg       0.54      0.67      0.54     93200\n",
      " weighted avg       0.95      0.84      0.88     93200\n",
      "\n",
      "[[76594 13295]\n",
      " [ 1725  1586]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "target_names = ['Positive (BH)', 'Negative']\n",
    "y_true=segmented_annot['label'].values\n",
    "y_pred=model_detections_df['label'].values\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
